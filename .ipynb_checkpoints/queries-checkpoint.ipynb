{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3b6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7c93051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v3/t8v18d8j7vd2fgp8d41vxr_80000gn/T/ipykernel_74710/3716745654.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('green_tripdata_2019-09.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('green_tripdata_2019-09.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "274f059f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-09-01 00:10:53</td>\n",
       "      <td>2019-09-01 00:23:46</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>189</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-09-01 00:31:22</td>\n",
       "      <td>2019-09-01 00:44:37</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97</td>\n",
       "      <td>225</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-09-01 00:50:24</td>\n",
       "      <td>2019-09-01 01:03:20</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-09-01 00:27:06</td>\n",
       "      <td>2019-09-01 00:33:22</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-09-01 00:43:23</td>\n",
       "      <td>2019-09-01 00:59:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112</td>\n",
       "      <td>198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.42</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0       2.0  2019-09-01 00:10:53   2019-09-01 00:23:46                  N   \n",
       "1       2.0  2019-09-01 00:31:22   2019-09-01 00:44:37                  N   \n",
       "2       2.0  2019-09-01 00:50:24   2019-09-01 01:03:20                  N   \n",
       "3       2.0  2019-09-01 00:27:06   2019-09-01 00:33:22                  N   \n",
       "4       2.0  2019-09-01 00:43:23   2019-09-01 00:59:54                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            65           189              5.0           2.00   \n",
       "1         1.0            97           225              5.0           3.20   \n",
       "2         1.0            37            61              5.0           2.99   \n",
       "3         1.0           145           112              1.0           1.73   \n",
       "4         1.0           112           198              1.0           3.42   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         10.5    0.5      0.5        2.36           0.0        NaN   \n",
       "1         12.0    0.5      0.5        0.00           0.0        NaN   \n",
       "2         12.0    0.5      0.5        0.00           0.0        NaN   \n",
       "3          7.5    0.5      0.5        1.50           0.0        NaN   \n",
       "4         14.0    0.5      0.5        3.06           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3         14.16           1.0        1.0   \n",
       "1                    0.3         13.30           2.0        1.0   \n",
       "2                    0.3         13.30           2.0        1.0   \n",
       "3                    0.3         10.30           1.0        1.0   \n",
       "4                    0.3         18.36           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9931c602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v3/t8v18d8j7vd2fgp8d41vxr_80000gn/T/ipykernel_74710/1218321523.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('green_tripdata_2019-09.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2019-09-18': 70.28,\n",
       " '2019-09-16': 114.3,\n",
       " '2019-09-26': 341.64,\n",
       " '2019-09-21': 135.53}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('green_tripdata_2019-09.csv')\n",
    "\n",
    "# Convert the 'lpep_pickup_datetime' column to datetime\n",
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "\n",
    "# List of dates to check\n",
    "dates_to_check = ['2019-09-18', '2019-09-16', '2019-09-26', '2019-09-21']\n",
    "\n",
    "# Initialize a dictionary to store the maximum trip distance for each date\n",
    "largest_trip_each_day = {}\n",
    "\n",
    "# Iterate through each date\n",
    "for date in dates_to_check:\n",
    "    # Filter the dataframe for the specific date and calculate the maximum trip distance\n",
    "    max_trip_distance = df[df['lpep_pickup_datetime'].dt.date == pd.to_datetime(date).date()]['trip_distance'].max()\n",
    "    largest_trip_each_day[date] = max_trip_distance\n",
    "\n",
    "# Display the results\n",
    "largest_trip_each_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39f6e65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15612"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])\n",
    "\n",
    "# Filter the DataFrame for trips that started and ended on September 18th, 2019\n",
    "trips_on_sept_18 = df[(df['lpep_pickup_datetime'].dt.date == pd.to_datetime('2019-09-18').date()) &\n",
    "                      (df['lpep_dropoff_datetime'].dt.date == pd.to_datetime('2019-09-18').date())]\n",
    "\n",
    "# Calculate the number of trips\n",
    "num_trips_on_sept_18 = len(trips_on_sept_18)\n",
    "\n",
    "num_trips_on_sept_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2429389d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pd.read_csv('taxi+_zone_lookup.csv')\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd22fed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v3/t8v18d8j7vd2fgp8d41vxr_80000gn/T/ipykernel_74710/112633864.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('green_tripdata_2019-09.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borough</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>96333.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>92271.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queens</td>\n",
       "      <td>78671.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Borough  total_amount\n",
       "1   Brooklyn      96333.24\n",
       "2  Manhattan      92271.30\n",
       "3     Queens      78671.71"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'df' is your main DataFrame and 'lookup' is your lookup DataFrame that contains the 'PULocationID' and 'Borough' columns.\n",
    "\n",
    "# Load your data into the DataFrame\n",
    "df = pd.read_csv('green_tripdata_2019-09.csv')\n",
    "lookup = pd.read_csv('taxi+_zone_lookup.csv')  # The path to your lookup table CSV\n",
    "\n",
    "\n",
    "# Convert 'lpep_pickup_datetime' to datetime\n",
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "\n",
    "# Filter the DataFrame for trips on September 18th, 2019\n",
    "df_sept_18 = df[df['lpep_pickup_datetime'].dt.date == pd.to_datetime('2019-09-18').date()]\n",
    "\n",
    "# Merge the trip data with the lookup table to associate each trip with a borough\n",
    "df_sept_18_with_boroughs = df_sept_18.merge(lookup, how='left', left_on='PULocationID', right_on='LocationID')\n",
    "\n",
    "# Filter out unknown boroughs\n",
    "df_known_boroughs = df_sept_18_with_boroughs[df_sept_18_with_boroughs['Borough'] != 'Unknown']\n",
    "\n",
    "# Group by borough and sum the total_amount, then filter for sums greater than 50000\n",
    "borough_totals = df_known_boroughs.groupby('Borough')['total_amount'].sum().reset_index()\n",
    "boroughs_over_50k = borough_totals[borough_totals['total_amount'] > 50000]\n",
    "\n",
    "# Find the top 3 boroughs with the highest total_amount\n",
    "top_3_boroughs = boroughs_over_50k.nlargest(3, 'total_amount')\n",
    "\n",
    "top_3_boroughs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b6e89dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v3/t8v18d8j7vd2fgp8d41vxr_80000gn/T/ipykernel_74710/750230317.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('green_tripdata_2019-09.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'JFK Airport'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your data into the DataFrame\n",
    "df = pd.read_csv('green_tripdata_2019-09.csv')\n",
    "zone_lookup = pd.read_csv('taxi+_zone_lookup.csv')  # The path to your lookup table CSV\n",
    "\n",
    "# Ensure datetime format is correct\n",
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "\n",
    "# Filter the trips for September 2019\n",
    "df_september = df[df['lpep_pickup_datetime'].dt.month == 9]\n",
    "\n",
    "# Merge with the zone lookup table to get the pickup zone names\n",
    "df_september = df_september.merge(zone_lookup, left_on='PULocationID', right_on='LocationID', suffixes=('', '_pickup'))\n",
    "\n",
    "# Filter for trips that were picked up in 'Astoria'\n",
    "astoria_trips = df_september[df_september['Zone'] == 'Astoria']\n",
    "\n",
    "# If the drop-off location ID is in a separate lookup table or needs to be merged differently, adjust the merge accordingly.\n",
    "\n",
    "# Find the record with the largest tip amount\n",
    "max_tip_record = astoria_trips.loc[astoria_trips['tip_amount'].idxmax()]\n",
    "\n",
    "# Get the drop-off location ID from the record with the largest tip\n",
    "max_tip_dropoff_location_id = max_tip_record['DOLocationID']\n",
    "\n",
    "# Lookup the zone name for the drop-off location\n",
    "max_tip_dropoff_zone = zone_lookup[zone_lookup['LocationID'] == max_tip_dropoff_location_id]['Zone'].values[0]\n",
    "\n",
    "max_tip_dropoff_zone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842e1ac3",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedColumn",
     "evalue": "column t.pulocationid does not exist\nLINE 4: JOIN taxi_lookup l ON t.PULocationID = l.LocationID\n                              ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedColumn\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m df1 \u001b[38;5;241m=\u001b[39m query_db(query1, conn)\n\u001b[1;32m     74\u001b[0m df2 \u001b[38;5;241m=\u001b[39m query_db(query2, conn)\n\u001b[0;32m---> 75\u001b[0m df3 \u001b[38;5;241m=\u001b[39m query_db(query3, conn)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# df4 = query_db(query4, conn)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Close the database connection\u001b[39;00m\n\u001b[1;32m     79\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m, in \u001b[0;36mquery_db\u001b[0;34m(query, conn, params)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_db\u001b[39m(query, conn, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cursor:\n\u001b[0;32m---> 18\u001b[0m         cursor\u001b[38;5;241m.\u001b[39mexecute(query, params)\n\u001b[1;32m     19\u001b[0m         columns \u001b[38;5;241m=\u001b[39m [desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m     20\u001b[0m         data \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "\u001b[0;31mUndefinedColumn\u001b[0m: column t.pulocationid does not exist\nLINE 4: JOIN taxi_lookup l ON t.PULocationID = l.LocationID\n                              ^\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Function to connect to the PostgreSQL database\n",
    "def connect_to_db():\n",
    "    return psycopg2.connect(\n",
    "        dbname=\"ny_taxi\",\n",
    "        user=\"root\",\n",
    "        password=\"root\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "# Function to execute query and return results as DataFrame\n",
    "def query_db(query, conn, params=None):\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(query, params)\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        data = cursor.fetchall()\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Establish connection to database\n",
    "conn = connect_to_db()\n",
    "\n",
    "# Queries\n",
    "# 1) How many taxi trips were totally made on September 18th 2019?\n",
    "query1 = \"\"\"\n",
    "SELECT COUNT(*) AS trip_count\n",
    "FROM taxi_table\n",
    "WHERE lpep_pickup_datetime >= '2019-09-18 00:00:00'\n",
    "AND lpep_dropoff_datetime < '2019-09-19 00:00:00';\n",
    "\"\"\"\n",
    "\n",
    "# 2) Which was the pick up day with the largest trip distance?\n",
    "query2 = \"\"\"\n",
    "SELECT lpep_pickup_datetime::date AS pickup_day, SUM(trip_distance) AS total_distance\n",
    "FROM taxi_table\n",
    "WHERE lpep_pickup_datetime::date IN ('2019-09-18', '2019-09-16', '2019-09-26', '2019-09-21')\n",
    "GROUP BY pickup_day\n",
    "ORDER BY total_distance DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "# 3) The 3 pick up Boroughs on '2019-09-18' with a sum of total_amount superior to 50000\n",
    "query3 = \"\"\"\n",
    "SELECT l.\"Borough\", SUM(t.\"total_amount\") AS total_amount\n",
    "FROM \"taxi_table\" t\n",
    "JOIN \"taxi_lookup\" l ON t.\"PULocationID\" = l.\"LocationID\"\n",
    "WHERE t.\"lpep_pickup_datetime\"::date = '2019-09-18'\n",
    "AND l.\"Borough\" != 'Unknown'\n",
    "GROUP BY l.\"Borough\"\n",
    "HAVING SUM(t.\"total_amount\") > 50000\n",
    "ORDER BY total_amount DESC\n",
    "LIMIT 3;\n",
    "\"\"\"\n",
    "\n",
    "# 4) For the passengers picked up in Astoria, the drop off zone with the largest tip in September 2019\n",
    "query4 = \"\"\"\n",
    "SELECT l2.Zone AS dropoff_zone, MAX(t.tip_amount) AS max_tip\n",
    "FROM taxi_table t\n",
    "JOIN taxi_lookup l1 ON t.PULocationID = l1.LocationID\n",
    "JOIN taxi_lookup l2 ON t.DOLocationID = l2.LocationID\n",
    "WHERE l1.Zone = 'Astoria'\n",
    "AND t.lpep_pickup_datetime >= '2019-09-01'\n",
    "AND t.lpep_pickup_datetime < '2019-10-01'\n",
    "GROUP BY l2.Zone\n",
    "ORDER BY max_tip DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "# Execute queries\n",
    "df1 = query_db(query1, conn)\n",
    "df2 = query_db(query2, conn)\n",
    "df3 = query_db(query3, conn)\n",
    "# df4 = query_db(query4, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display results\n",
    "df1, df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa9d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
